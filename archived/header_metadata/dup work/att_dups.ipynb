{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emails\n",
    "import hme\n",
    "import sre\n",
    "import uts\n",
    "import re\n",
    "import csv\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bitnami/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emailstext = emails.getAll(\"allfilenames.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bmstats(bmpgl_emailstext):\n",
    "    blankpgs = []\n",
    "    noemails = []\n",
    "    yesemails = []\n",
    "    sa = []\n",
    "    listbms = re.split(\"BOOKMARKend---\",bmpgl_emailstext)\n",
    "    for bm in listbms:\n",
    "        listTS = uts.getTS(bm)\n",
    "        listSo = sre.findRawSenders_pg(bm)\n",
    "        deqfile = re.findall(\"deq.*_X\",bm)\n",
    "        nowords = re.findall(\"^\\n*\\W*[\\x0cdeq[_0-9b]+.txt---endPAGE]+---$\",bm)\n",
    "        if nowords != []: # no text\n",
    "            for noword in nowords:\n",
    "                sa.append(noword)\n",
    "                noword = re.sub('\\n','',noword)\n",
    "                nochar = re.findall(\"^\\s*\\x0cdeq[_0-9b]+.txt$\",noword)\n",
    "                nolett = re.findall(\"^\\W*\\x0cdeq[_0-9b]+.txt$\",noword)\n",
    "                for nos in nochar: #no text\n",
    "                    blankpgs.append(bm)\n",
    "        elif nowords == []: #there is text\n",
    "            if listTS == [] and listSo == []: #no email\n",
    "                noemails.append(bm)\n",
    "            if listTS != [] or listSo != []: #yes email\n",
    "                yesemails.append(bm)\n",
    "    return noemails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "noe = bmstats(emailstext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1253"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.262669801712036 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "listtokem = []\n",
    "for att in noe:\n",
    "    tokem =nltk.word_tokenize(att)\n",
    "    listtokem.append(tokem)\n",
    "print(\"%s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg=[]\n",
    "for tok in (listtokem):\n",
    "    g = len(tok)\n",
    "    d = tok\n",
    "    new = (g)\n",
    "    hg.append(new)\n",
    "hg.sort()\n",
    "u = list(dict.fromkeys(hg))\n",
    "u.sort()\n",
    "#print(u) #list of lengths, to know cuttoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=[]\n",
    "for tok in (listtokem):\n",
    "    g = len(tok)\n",
    "    d = tok\n",
    "    new = (d,g)\n",
    "    h.append(new)\n",
    "h.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setpairs(listtokem): #pairs every bm with each other\n",
    "    dupspairs = []\n",
    "    dups = []\n",
    "    comparer = []\n",
    "    xx = []\n",
    "    for tokems in listtokem:\n",
    "        listtokem1=[] \n",
    "        for dems in listtokem:\n",
    "            if dems != tokems:\n",
    "                listtokem1.append(dems) #new list with everything but given tokem\n",
    "        for tokems1 in listtokem1:# compare tokem to every other tokem1\n",
    "            if [tokems,tokems1] not in comparer: #and [tokems1,tokems] not in comparer:\n",
    "                comparer.append([tokems,tokems1])\n",
    "    xx.extend(comparer)\n",
    "    return xx\n",
    "def checklgt(xx): #if they have similar lengths (number of tokens), returns\n",
    "    xxa = []\n",
    "    no = []\n",
    "    for pair in xx:\n",
    "        p1 = pair[0]\n",
    "        p2 = pair[1]\n",
    "        tok1 = p1[0]\n",
    "        tok2 = p2[0]\n",
    "        if len(p1[0]) > 4 and len(p2[0])>4:\n",
    "            deqf1 = tok1[-5]\n",
    "            deqf2 = tok2[-5]\n",
    "        if (p1[1])<(p2[1]):\n",
    "            if (p1[1])/(p2[1]) > .8:\n",
    "                xxa.append(pair)\n",
    "            else:\n",
    "                no.extend(pair)\n",
    "                #pass\n",
    "        elif (p1[1])>(p2[1]):\n",
    "            if (p2[1])/(p1[1]) > .8:\n",
    "                xxa.append(pair)\n",
    "            else:\n",
    "                no.extend(pair)\n",
    "                #pass\n",
    "        elif len(p1)==len(p2):\n",
    "            xxa.append(pair)\n",
    "    return xxa\n",
    "def matchtoks(xxa): #if over 80% of tokens match, returns\n",
    "    no=[]\n",
    "    dups = []\n",
    "    dupairfs = []\n",
    "    for paira in xxa:\n",
    "        match1 = []\n",
    "        match2 = []\n",
    "        pa1 = paira[0]\n",
    "        pa2 = paira[1]\n",
    "        tok1 = pa1[0]\n",
    "        tok2 = pa2[0]\n",
    "        if len(pa1[0]) > 4 and len(pa2[0]) >4:\n",
    "            deqfa1 = tok1[-5]\n",
    "            deqfa2 = tok2[-5]\n",
    "        avg = (len(tok1)+len(tok2))/2\n",
    "        for wd in tok1:\n",
    "            if wd in tok2:\n",
    "                match1.append(wd)\n",
    "        for wd in tok2:\n",
    "            if wd in tok1:\n",
    "                match2.append(wd)\n",
    "        score = (len(match1)+len(match2))/2\n",
    "        if score/avg > .8:\n",
    "            dupairf = [deqfa1,deqfa2]\n",
    "            dupairfs.append(dupairf)\n",
    "            dupair = [tuple(pa1),tuple(pa2)]\n",
    "            dupspairs.append(dupair)\n",
    "            dups.extend(paira)\n",
    "        else:\n",
    "            no.extend(paira)\n",
    "            pass\n",
    "    def fwdNbckwd(pairlists):\n",
    "        reww = []\n",
    "        for yus in pairlists:\n",
    "            new = [yus[1],yus[0]]\n",
    "            reww.append(new)\n",
    "        newlist = list(reww + pairlists)\n",
    "        return newlist\n",
    "    dupairfsx2 = fwdNbckwd(dupairfs)\n",
    "    return dupairfsx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(u):\n",
    "        ndl = {}\n",
    "        nts = []\n",
    "        for lists in u:\n",
    "            f = lists[0]\n",
    "            s = lists[1]\n",
    "            newdic = {}\n",
    "            if f not in [*ndl]:\n",
    "                newdic[f] = [s]\n",
    "                ndl.update(newdic)\n",
    "            else:\n",
    "                ndl[f].append(s)\n",
    "                pass\n",
    "        lndl = tolist(ndl)\n",
    "        return lndl\n",
    "def combine1(u):\n",
    "        ndl = {}\n",
    "        nts = []\n",
    "        for lists in u:\n",
    "            f = lists[0]\n",
    "            s = lists[1]\n",
    "            newdic = {}\n",
    "            if f not in [*ndl]:\n",
    "                newdic[f] = s\n",
    "                ndl.update(newdic)\n",
    "            else:\n",
    "                ndl[f].append(s)\n",
    "                pass\n",
    "        lndl = tolist(ndl)\n",
    "        lndl.extend(nts)\n",
    "        return lndl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def smoothout(x):\n",
    "    def elimrepeats(medatt4):\n",
    "        newu = []\n",
    "        for xxxs in medatt4:\n",
    "            xxxs.sort()\n",
    "            du1d = list(dict.fromkeys(tuple(xxxs)))\n",
    "            newu.append(tuple(du1d))\n",
    "        len(newu)\n",
    "        newud = list(dict.fromkeys(newu))\n",
    "        newud.sort()\n",
    "        len(newu)\n",
    "        def orderbylen(elem):\n",
    "            return len(elem)\n",
    "        newud.sort(key=orderbylen)\n",
    "        newud1 = emails.revlist(newud)\n",
    "        newud1\n",
    "        return newud1\n",
    "    def consolidate(newud1):\n",
    "        tu = []\n",
    "        du = []\n",
    "        for tuples in newud1:\n",
    "            for deqs in tuples:\n",
    "                if deqs not in du:\n",
    "                    du.append(deqs)\n",
    "                    tu.append(tuples)\n",
    "                else:\n",
    "                    pass\n",
    "        tu1 = list(dict.fromkeys(tu))\n",
    "        nu = []\n",
    "        for xxxs in tu1:\n",
    "            lxxxs = list(xxxs)\n",
    "            lxxxs.sort()\n",
    "            du1d = list(dict.fromkeys(tuple(lxxxs)))\n",
    "            nu.append(tuple(du1d))\n",
    "        nu1 = list(dict.fromkeys(nu))\n",
    "        nu1.sort()\n",
    "        return nu1\n",
    "    def elimrepeats2(nu1):\n",
    "        nu2 = []\n",
    "        for nus in nu1:\n",
    "            nu2.append(nus)\n",
    "        yo = []\n",
    "        for nus in nu1:\n",
    "            for deqs in nus:\n",
    "                for nups in nu1:\n",
    "                    if nus != nups and deqs in nups:\n",
    "                        new = list(nus + nups)\n",
    "                        new1 = list(dict.fromkeys(new))\n",
    "                        new1.sort()\n",
    "                        yo.append(tuple(new1))\n",
    "\n",
    "        yos = list(dict.fromkeys(yo))\n",
    "        broo = []\n",
    "        for tups in yos:\n",
    "            for deqs in tups:\n",
    "                for nups in nu1:\n",
    "                    if deqs in nups and nups in nu2:\n",
    "                        nu2.remove(nups)\n",
    "\n",
    "        b = list(nu2 + yos)   \n",
    "        bb = list(dict.fromkeys(b))\n",
    "        bb.sort()\n",
    "        #CHECK\n",
    "        all1 = []\n",
    "        for tups in bb:\n",
    "            for deqs in tups:\n",
    "                all1.append(deqs)\n",
    "        all2 = list(dict.fromkeys(all1))\n",
    "        if len(all1) == len(all2):\n",
    "            return bb\n",
    "        else:\n",
    "            print(\"error\")\n",
    "    return elimrepeats2(consolidate(elimrepeats(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tolist(r):\n",
    "        listr = []\n",
    "        for key, value in r.items():\n",
    "            v = []\n",
    "            v.append(key)\n",
    "            v.extend(value)\n",
    "            listr.append(v)\n",
    "        return listr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "def begend(words):\n",
    "    beg = words[0:100]\n",
    "    end = words[-106:]\n",
    "    begend = list(beg + end)\n",
    "    return begend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "short=[]\n",
    "blank=[]\n",
    "med=[]\n",
    "medlong=[]\n",
    "long=[]\n",
    "sprlong=[]\n",
    "rlylong=[]\n",
    "rlyrlylong = []\n",
    "for hs in h:\n",
    "    if hs[1] == 5:\n",
    "        blank.append(hs)\n",
    "    elif hs[1] in range(6,13):\n",
    "        short.append(hs)\n",
    "    elif hs[1] in range(14,216):\n",
    "        new = (begend(hs[0]),hs[1])\n",
    "        med.append(hs)\n",
    "    elif hs[1] in range(217,637):\n",
    "        new = (begend(hs[0]),hs[1])\n",
    "        medlong.append(new)\n",
    "    elif hs[1] in range(638,1003):\n",
    "        new = (begend(hs[0]),hs[1])\n",
    "        long.append(new)\n",
    "    elif hs[1] in range(1004,1687):\n",
    "        new = (begend(hs[0]),hs[1])\n",
    "        sprlong.append(new)\n",
    "    elif hs[1] in range(1688,5108):\n",
    "        new = (begend(hs[0]),hs[1])\n",
    "        rlylong.append(new)\n",
    "    elif hs[1] in range(5109,7871):\n",
    "        new = (begend(hs[0]),hs[1])\n",
    "        rlyrlylong.append(new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10443806648254395 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "shatt1 = setpairs(short)\n",
    "shatt2 = checklgt(shatt1)\n",
    "shatt3 = matchtoks(shatt2)\n",
    "shatt3.sort()\n",
    "shatt4 = combine(shatt3)\n",
    "shatt4.sort()\n",
    "shatt5 = smoothout(shatt4)\n",
    "print(\"%s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.45188283920288 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "medatt1 = setpairs(med)\n",
    "medatt2 = checklgt(medatt1)\n",
    "medatt3 = matchtoks(medatt2)\n",
    "medatt3.sort()\n",
    "medatt4 = combine(medatt3)\n",
    "medatt4.sort()\n",
    "medatt5 = smoothout(medatt4)\n",
    "print(\"%s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.3269476890564 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "medlatt1 = setpairs(medlong)\n",
    "medlatt2 = checklgt(medlatt1)\n",
    "medlatt3 = matchtoks(medlatt2)\n",
    "medlatt3.sort()\n",
    "medlatt4 = combine(medlatt3)\n",
    "medlatt4.sort()\n",
    "medlatt5 = smoothout(medlatt4)\n",
    "print(\"%s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.94878458976746 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "longatt1 = setpairs(long)\n",
    "longatt2 = checklgt(longatt1)\n",
    "longatt3 = matchtoks(longatt2)\n",
    "longatt3.sort()\n",
    "longatt4 = combine(longatt3)\n",
    "longatt4.sort()\n",
    "longatt5 = smoothout(longatt4)\n",
    "print(\"%s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.68197274208069 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "sprlongatt1 = setpairs(sprlong)\n",
    "sprlongatt2 = checklgt(sprlongatt1)\n",
    "sprlongatt3 = matchtoks(sprlongatt2)\n",
    "sprlongatt3.sort()\n",
    "sprlongatt4 = combine(sprlongatt3)\n",
    "sprlongatt4.sort()\n",
    "sprlongatt5 = smoothout(sprlongatt4)\n",
    "print(\"%s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.112900733947754 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "rlylongatt1 = setpairs(rlylong)\n",
    "rlylongatt2 = checklgt(rlylongatt1)\n",
    "rlylongatt3 = matchtoks(rlylongatt2)\n",
    "rlylongatt3.sort()\n",
    "rlylongatt4 = combine(rlylongatt3)\n",
    "rlylongatt4.sort()\n",
    "rlylongatt5 = smoothout(rlylongatt4)\n",
    "print(\"%s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38559794425964355 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "rlyrlylongatt1 = setpairs(rlyrlylong)\n",
    "rlyrlylongatt2 = checklgt(rlyrlylongatt1)\n",
    "rlyrlylongatt3 = matchtoks(rlyrlylongatt2)\n",
    "rlyrlylongatt3.sort()\n",
    "rlyrlylongatt4 = combine(rlyrlylongatt3)\n",
    "rlyrlylongatt4.sort()\n",
    "rlyrlylongatt5 = smoothout(rlyrlylongatt4)\n",
    "print(\"%s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1252"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = []\n",
    "for tok in listtokem:\n",
    "    if len(tok) >4:\n",
    "        deq = tok[-5]\n",
    "        r.append(deq)\n",
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "659"
      ]
     },
     "execution_count": 788,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldups = list(shatt5+medatt5+medlatt5+longatt5+sprlongatt5+rlylongatt5+rlyrlylongatt5)\n",
    "alldups_deqs = []\n",
    "for tups in alldups:\n",
    "    for deqs in tups:\n",
    "        alldups_deqs.append(deqs)\n",
    "len(alldups_deqs)\n",
    "alldd=[]\n",
    "for d in alldups_deqs:\n",
    "    nd = re.findall(\"deq.*txt\",d)\n",
    "    alldd.extend(nd)\n",
    "len(alldd)\n",
    "len(list(dict.fromkeys(alldd)))\n",
    "#len(alldd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('deq24_b217_541_541_1.txt',\n",
       "  'deq24_b396_980_980_1.txt',\n",
       "  'deq24_b669_1724_1724_1.txt',\n",
       "  'deq24_b291_700_700_1.txt',\n",
       "  'deq24_b257_636_636_1.txt',\n",
       "  'deq24_b230_574_574_1.txt',\n",
       "  'deq24_b535_1368_1368_1.txt',\n",
       "  'deq24_b228_571_571_1.txt',\n",
       "  'deq24_b49_113_113_1.txt',\n",
       "  'deq24_b155_393_393_1.txt',\n",
       "  'deq24_b645_1675_1675_1.txt',\n",
       "  'deq24_b477_1212_1212_1.txt',\n",
       "  'deq24_b706_1888_1888_1.txt',\n",
       "  'deq24_b356_915_915_1.txt',\n",
       "  'deq24_b303_720_720_1.txt',\n",
       "  'deq24_b312_733_733_1.txt',\n",
       "  'deq24_b280_687_687_1.txt',\n",
       "  'deq24_b339_880_880_1.txt',\n",
       "  'deq24_b98_263_263_1.txt',\n",
       "  'deq24_b310_731_731_1.txt',\n",
       "  'deq24_b212_532_532_1.txt',\n",
       "  'deq24_b653_1691_1691_1.txt',\n",
       "  'deq24_b308_728_728_1.txt',\n",
       "  'deq24_b646_1676_1676_1.txt',\n",
       "  'deq24_b354_913_913_1.txt',\n",
       "  'deq24_b156_394_394_1.txt',\n",
       "  'deq24_b64_140_140_1.txt'),\n",
       " ('deq11_b147_866_866_1.txt', 'deq11_b96_211_211_1.txt'),\n",
       " ('deq11_b14_23_24_2.txt', 'deq14_b128_305_306_2.txt')]"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldups[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593"
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allnond=[]\n",
    "for d in r:\n",
    "    nd = re.findall(\"deq.*txt\",d)\n",
    "    allnond.extend(nd)\n",
    "alldups_deqs1 = []\n",
    "for d in alldups_deqs:\n",
    "    nd = re.findall(\"deq.*txt\",d)\n",
    "    alldups_deqs1.extend(nd)\n",
    "alldups1 = []\n",
    "for d in alldups:\n",
    "    newd = []\n",
    "    for ds in d:\n",
    "        nd = re.findall(\"deq.*txt\",ds)\n",
    "        newd.extend(nd)\n",
    "    newd.sort()\n",
    "    alldups1.append(tuple(newd))\n",
    "len(allnond)\n",
    "notdups = []\n",
    "for rs in allnond:\n",
    "    if rs not in alldd:\n",
    "        notdups.append(rs)\n",
    "len(notdups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeFir(elem):\n",
    "    if type(elem) == str:\n",
    "        return elem\n",
    "    if type(elem) == tuple:\n",
    "        return elem[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = list(alldups1 + notdups)\n",
    "total.sort(key=takeFir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deq01_b24_1845_3570_1726.txt',\n",
       " 'deq02_b299_3506_3506_1.txt',\n",
       " 'deq04_b20_1412_1426_15.txt',\n",
       " 'deq04_b270_3577_3579_3.txt',\n",
       " 'deq04_b77_2967_3228_251.txt',\n",
       " ('deq11_b102_237_239_3.txt',\n",
       "  'deq14_b242_925_928_4.txt',\n",
       "  'deq14_b319_1065_1067_3.txt',\n",
       "  'deq14_b326_1077_1080_4.txt',\n",
       "  'deq14_b333_1095_1098_4.txt',\n",
       "  'deq14_b338_1106_1109_4.txt',\n",
       "  'deq14_b380_1260_1263_4.txt',\n",
       "  'deq14_b382_1266_1268_3.txt',\n",
       "  'deq15_b13_80_83_4.txt',\n",
       "  'deq15_b35_117_120_4.txt',\n",
       "  'deq15_b38_125_128_4.txt',\n",
       "  'deq25_b59_753_755_3.txt'),\n",
       " ('deq11_b103_240_241_2.txt', 'deq24_b577_1492_1493_2.txt'),\n",
       " 'deq11_b104_242_242_1.txt',\n",
       " 'deq11_b105_243_243_1.txt',\n",
       " 'deq11_b10_17_18_2.txt']"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total[0:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
